# Redis开发与运维-note（二）

## 3 小功能大用处

### 3.1 慢查询分析

1、指令的生命周期

![](../.gitbook/assets/image%20%2880%29.png)

慢查询只统计了步骤三的时间，所以没有慢查询并不代表客户端没有超时问题。

通过 slowlog-log-slower-than 来设置超过多少微秒需要记录；设置为0，则记录所有的查询。

通过 slowlog-max-len 说明慢查询日志最多存储多少条，超过之后，再插入时，会把最早的指令移除。

### 3.2  Pipeline

将一组Redis命令进行组装，通过一次RTT 传输给Redis, 再将这组Redis命令的执行结果按顺序返回给客户端，节省了多次RTT 时间。

![](../.gitbook/assets/image%20%2878%29.png)

2、原生批量命令与pipeline

可以使用pipeline 模拟出批量操作的效果，但是在使用时要注意它与原生批量命令的区别，具体包含如下几点：

* 原生批量命令是原子的，pipeline是非原子的
* 原生批量命令是一个命令对应多个key, pipeline 支持多个命令
* 原生批量命令是Redis服务端支持实现的，而pipeline 需要服务端和客户端共同实现。

3、最佳实践

pipeline 虽然好用，但是每次组装的命令个数不能没有节制，否则一次组装pipeline数据量过大，一方面增加客户端的等待时间，另一方面会造成一定的网络阻塞，可以讲一次包含大量命令的pipeline 拆分成多次较小的pipeline来完成。

### 3.3 事务与Lua

为了保证多条命令组合的原子性。

#### 3.3.1 事务

事务保证原子性。

1、执行指令

```text
multi 命令代表事务开始，exec 代表事务结束，它们之间的命令是原子顺序执行的。
如果要停止事务，可是使用discard命令。
```

Redis 的事务并不支持回滚功能，需要开发人员自己修复这类问题。同时无法实现命令之间的逻辑关系计算。



#### 3.3.2 Lua 脚本语言

1、好处：

* lua 脚本在Redis中是原子执行的
* lua 脚本可以常驻Redis内存，实现复用
* lua 脚本可以将多条命令一次性打包，减少网络开销。

2、缺点：如果开始执行，会一直占据redis 服务端线程，导致其他请求得不到处理，使用不当破坏性是难以想象的。



2、Redis 中执行lua 脚本有两种方法：eval 和 evalsha

```text
eval 脚本内容 key个数 key列表 参数列表

```

![](../.gitbook/assets/image%20%2872%29.png)

3、evalsha 

首先要将lua 脚本加载到Redis服务端，得到该脚本的sha1 校验和，evelsha 命令使用sha1 作为参数直接执行对应的lua 脚本，避免每次发送lua 脚本的开销。这样客户端不需要每次执行脚本内容，而脚本也会常驻在服务端。

（1）加载脚本

（2）执行脚本

### 3.4 Bitmaps

bitmaps 本身不是一种数据结构，实际上他就是字符串，但是它可以对字符串的位进行操作。

以位为单位的数组，数组的每个单元只存储0和1，数组的下标在bitmaps 中叫做偏移量。



## 4 客户端

### 4.1 客户端通信协议

1、Redis 基于TCP 之上，制定了RESP\(Redis serialization protocol\) ，高效，既能被机器解析，又能被人类识别。

### 4.2 java 客户端-jedis

1、

![](../.gitbook/assets/image%20%2875%29.png)

连接池可以复用连接，并且可以限制jedis 对象的个数，不至于过多，造成连接泄漏。

### 4.3 客户端常见异常

1、无法从连接池获取到连接

为什么？

```text
1、高并发下连接池设置过小，出现供不应求
2、客户端没有正确使用连接池，比如没有释放
3、客户端存在慢查询，这些慢查询导致持有的jedis 对象归还速度慢
4、服务端：服务端由于一些原因造成了客户端命令执行过程的阻塞
```

2、客户端读写超时

```text
1、读写超时时间设置过短
2、命令本身比较慢
3、客户端与服务端网络不正常
4、Redis 自身发生阻塞
```

3、客户端连接超时

```text
1、连接超时设置的过短
2、Redis发生阻塞，造成tcp-backlog 已满，造成新的连接失败
3、客户端与服务端网络不正常
```

4、客户端缓冲区异常

```text
1、输出缓冲区满
2、长时间闲置连接被服务端主动断开
3、不正常并发读写

```

5、Lua 脚本正在执行

6、Redis 正在加载持久化文件



7、Redis 使用的内存超过maxmemory 配置

8、客户端连接数过大

```text
1、客户端：由于应用方对于Redis客户端使用不当造成的
2、服务端：
```

## 5 持久化

### 5.1 RDB

rdb 持久化是把当前进程数据生成快照保存到硬盘的过程。

1、触发机制

手动触发 分为save 和 bgsave

> save: 阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。

> bgsave：Redis 进程执行fork 操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。对save 阻塞问题做了优化。

除了执行命令手动触发外，Redis内部还存在自动触发RDB的持久化机制：



2、bgsave 运作流程

![](../.gitbook/assets/image%20%2886%29.png)

3、优缺点

优点：

适用于备份，全量复制等场景。加载RDB 恢复数据远远快于AOF 的方式。

缺点：  
没办法做到实时持久化/秒级持久化。因为bgsave 每次运行都要执行fork操作创建子进程，属于重量级操作，频繁操作成本过高。



### 5.2 AOF（append only file）

以独立日志的方式记录每次写命令，重启时再执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性。

1、开启AOF 需要设置appendonly yes, 默认不开启。

2、工作流程：

命令写入（append）  
文件同步（sync）  
文件重写（rewrite）  
重启加载（load）



![](../.gitbook/assets/image%20%2884%29.png)

> （1）所有的写入命令会追加到aof\_buf\(缓冲区\)中
>
> （2）AOF 缓冲区根据对应的策略向硬盘做同步操作
>
> （3）随着AOF 文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的
>
> （4）当Redis服务器重启时，可以加载AOF文件进行数据恢复。

3、同步间隔：

always: 每次写入都要同步AOF文件  
no: 由操作系统控制，但是由于操作系统每次同步AOF文件的周期不可用，而会加大每次同步硬盘的数据量，虽然提升了性能，但是数据安全性无法保证。  
everysec: 1s 同步一次。

4、重写机制：  
重写之后，AOF文件会变小，因为：  


```text
1。进程内已经超时的数据不再写入文件
2、旧的AOF文件包含无效命令，新的AOF文件只保留最终数据的写入命令
3、多条写命令合并为一个
4.
```

5、触发

手动触发：bgrewriteaof

自动触发：auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 参数确定自动触发机制。

![](../.gitbook/assets/image%20%2882%29.png)

6、重启加载  


![](../.gitbook/assets/image%20%2887%29.png)

```

```

## 6 复制

### 6.1 配置

1、从主节点复制到从节点。

在从节点上执行如下指令：

```text
slaveof {masterHost} {masterPort}
```

断开复制：

在从节点上执行 slaveof no one 来断开复制。

通过slaveof 命令还可以实现切主操作（切主操作是指把当前从节点对主节点的复制切换到另外一个主节点），执行slaveof {newMasterHost} {newMasterPort} 即可。



切主操作流程：

```text
1 断开与旧主节点复制关系
2 与新主节点建立复制关系
3 删除从节点当前所有数据
4 对新主节点进行复制操作
```

2、传输延迟

主从节点一般部署在不同的机器上，主从延迟必须考虑。Redis提供了repl-disable-tcp-nodelay 参数用于控制是否关闭TCP-NODELAY , 默认关闭。

当关闭时：主节点产生的命令数据无论大小都会及时发送给从节点，这样主从延迟小了，但增加网络带宽的消耗。适用于主从网络环境好的场景；

当打开时：主节点会合并较小的tcp 数据包从而节省带宽。这样节省了带宽但增大了主从之间的延迟。适用于网络环境复杂 或者带宽紧张的场景。

### 6.2 拓扑

#### 6.2.1 一主一从



#### 6.2.2 一主多从

使得应用端可以利用多个从节点实现读写分离。对于读多写少的场景，可以把命令发送到从节点来分担主节点压力。

#### 6.2.3 树状主从结构

使得从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。



### 6.3 原理

#### 6.3.1 复制过程

![](../.gitbook/assets/image%20%2881%29.png)

（1）从节点保存主节点信息

（2）主从建立socket 连接

从节点建立一个socket 套接字，专门用于接受主节点发送的复制命令。

（3）发送ping 命令

目的：

```text
1、检测主从之间套接字是否可用
2、检测主节点当前是否可接受处理命令
```



（4）权限验证

（5）同步数据集

主节点会把持有的数据全部发送给从节点。

（6）命令持续复制  
当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从一致。



#### 6.3.2 数据同步

1、全量复制

一般用于初次复制场景。

2、部分复制

用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。

3、复制偏移量

主节点会记录发送给从节点的偏移量，当然从节点也会记录自身的偏移量。如果主节点偏移量跟从节点偏移量 二者之间差距比较大，说明可能存在网络延迟或者命令阻塞。

4、复制积压缓冲区

保存在主节点上的一个固定长度的队列，默认是1M，当主节点有连接的从节点时被创建，这时主节点响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。用于部分复制和复制命令丢失的数据补救。

5、主节点运行ID  

每个节点都有一个唯一运行ID. 并且Redis关闭再启动后，运行ID 会随之改变。

6、psync 命令

从节点使用psync 命令完成部分复制和全量复制功能。

psync {master id} {offset}

7、全量复制

![](../.gitbook/assets/image%20%2883%29.png)

8、部分复制

对全量复制的一个补充。通过psync 命令实现。

![](../.gitbook/assets/image%20%2885%29.png)

9、主从之间的心跳

主从节点在建立复制后，它们之间维护者长连接并彼此发送心跳命令。



### 

