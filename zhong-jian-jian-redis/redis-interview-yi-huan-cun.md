# Redis interview\(一\) 缓存

## 1 缓存是什么？用途是？

> 缓存的目的是把读写速度慢的介质的数据保存到读写速度快的介质上，从而提高读写速度，减少时间消耗。

## 2 缓存算法

* LRU: 最近最少使用
* LFU: 最不经常使用
* FIFO 先进先出

## 3 常见的缓存工具和框架

本地缓存：guava/ehcache/caffeine. Ehcache 功能更丰富，Caffeine 性能比其他两者好。

分布式缓存：Redis、memcached.

## 4 用了缓存，带来的问题

### 4.1 写入问题：

* 缓存何时 **写入**? 并且写时避免并发重复写入？
* 缓存如何**失效**?
* 缓存和DB的**一致性**如何保证？

### 4.2 经典三连问

* 如何避免缓存**穿透**的问题？
* 如何避免缓存**击穿**的问题？
* 如何避免缓存**雪崩**的问题？

## 5 查询缓存报错，如果提高可用性？

一般情况下，如果异常出现，需要手动捕获这个异常，并且记录日志，从数据库返回数据给用户，而不应该导致业务不可用。

## 6 缓存穿透

### 6.1 缓存穿透讲解

缓存穿透，是指查询一个一定**不存在**的数据，由于缓存是不命中时被动写，并且处于容错考虑，如果从 DB 查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，失去了缓存的意义。流量大时，可能DB就直接挂掉了。

![](../.gitbook/assets/image%20%28123%29.png)

一定要注意，**缓存穿透**，指的是查询一个**不存在**的数据，很容器和我们要讲到的**缓存击穿**搞混淆。



### 6.2 解决方案

#### 6.2.1 方案一、缓存空对象

当从DB查询数据为空时，将这个空结果进行缓存，具体的值需要使用特殊的标识，能和真正缓存的数据区分开。另外，需要设置较短的过期时间，一般建议不要超过5分钟。



这个方案的缺点：

第一，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间

第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5 分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。



#### 6.2.2 使用布隆过滤器

在缓存服务的基础上，构建 BloomFilter 数据结构，在 BloomFilter 中存储对应的 KEY 是否存在，如果存在，说明该 KEY 对应的值**不为空**。那么整个逻辑的如下：

* 1、根据 KEY 查询【BloomFilter 缓存】。如果不存在对应的值，直接返回；如果存在，继续向下执行。【后续的流程，就是标准的流程】
* 2、根据 KEY 查询在【数据缓存】的值。如果存在值，直接返回；如果不存在值，继续向下执行。
* 3、查询 DB 对应的值，如果存在，则更新到缓存，并返回该值。

**当然，使用 BloomFilter 布隆过滤器的话，需要提前将已存在的 KEY ，初始化存储到【BloomFilter 缓存】中。**

![](../.gitbook/assets/image%20%28118%29.png)

#### **6.2.3 方案对比**

![](../.gitbook/assets/image%20%28120%29.png)

实际情况下，使用方案二比较多。因为，相比方案一来说，更加节省内容，对缓存的负荷更小。

## 7 缓存雪崩

### 7.1 雪崩描述

缓存雪崩，是指缓存由于某些原因无法提供服务\( 例如，缓存挂掉了 \)，所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。

### 7.2 解决方案

多方面解决：

1）缓存高可用

通过搭建缓存的高可用，避免缓存挂掉导致无法提供服务的情况，从而降低出现缓存雪崩的情况。

2）本地缓存

如果使用本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。

当然，引入本地缓存也会有相应的问题，例如说：

* 本地缓存的实时性怎么保证？
  * 方案一，可以引入消息队列。在数据更新时，发布数据更新的消息；而进程中有相应的消费者消费该消息，从而更新本地缓存。
  * 方案二，设置较短的过期时间，请求时从 DB 重新拉取。
  * 方案三，使用 [「如果避免缓存”击穿”的问题？」](http://svip.iocoder.cn/Cache/Interview/#) 问题的【方案二】，手动过期。
* 每个进程可能会本地缓存相同的数据，导致数据浪费？
  * 方案一，需要配置本地缓存的过期策略和缓存数量上限。

3）请求 DB 限流

通过限制 DB 的每秒请求数，避免把 DB 也打挂了。这样至少能有两个好处：

1. 可能有一部分用户，还可以使用，系统还没死透。
2. 未来缓存服务恢复后，系统立即就已经恢复，无需再处理 DB 也挂掉的情况。

当然，被限流的请求，我们最好也要有相应的处理，走【服务降级】，提供一些默认的值，或者友情提示，甚至空白的值也行。

如果我们使用 Java ，则可以使用 Guava RateLimiter、Sentinel、Hystrix 实现限流的功能。

4）提前演练

在项目上线前，演练缓存宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。

## 8 缓存击穿

### 8.1 什么事缓存击穿？

缓存击穿，是指某个**极度“热点”**数据在某个时间点过期时，恰好在这个时间点对这个 KEY 有大量的并发请求过来，这些请求发现缓存过期一般都会从 DB 加载数据并回设到缓存，但是这个时候大并发的请求可能会瞬间 DB 压垮。



区别：

* 和缓存“雪崩“”的区别在于，击穿针对某一 KEY 缓存，后者则是很多 KEY 。
* 和缓存“穿透“”的区别在于，击穿 中 这个 KEY 是真实存在对应的值的。

### 8.2 解决方案

#### 8.2.1 方案一 使用互斥锁

请求发现缓存不存在后，去查询DB前，使用分布式锁，保证只有且只有一个线程去查DB，并更新到缓存。



* 1、获取分布式锁，直到成功或超时。如果超时，则抛出异常，返回。如果成功，继续向下执行。
* 2、获取缓存。如果存在值，则直接返回；如果不存在，则继续往下执行。😈 因为，获得到锁，可能已经被“那个”线程去查询过 DB ，并更新到缓存中了。
* 3、查询 DB ，并更新到缓存中，返回值。

#### 8.2.2 手动过期

缓存上从不设置过期时间，功能上将过期时间存储在key 对应的value 中。流程如下：



* 1、获取缓存。通过 VALUE 的过期时间，判断是否过期。如果未过期，则直接返回；如果已过期，继续往下执行。
* 2、通过一个后台的异步线程进行缓存的构建，也就是“手动”过期。通过后台的异步线程，保证有且只有一个线程去查询 DB。
* 3、同时，虽然 VALUE 已经过期，还是直接返回。通过这样的方式，保证服务的可用性，虽然损失了一定的时效性。



## 9 缓存和DB的一致性保证

### 9.1 产生原因

* 并发场景下，导致读取老的DB数据，更新到缓存中
  * 更新 DB 数据之前，先删除 Cache 的数据。在低并发量下没什么问题，但是在高并发下，就会存在问题。在\(删除 Cache 的数据, 和更新 DB 数据\)时间之间，恰好有一个请求，我们如果使用**被动读**，因为此时 DB 数据还是老的，又会将老的数据写入到 Cache 中。
* 缓存和DB的操作，不在一个事务中，可能只有一个DB操作成功，而另一个cache操作失败。

当然，有一点我们要注意，缓存和 DB 的一致性，我们指的更多的是最终一致性。我们使用缓存只要是提高读操作的性能，真正在写操作的业务逻辑，还是以数据库为准。例如说，我们可能缓存用户钱包的余额在缓存中，在前端查询钱包余额时，读取缓存，在使用钱包余额时，读取数据库。

### 9.2 解决方案

#### 9.2.1 将缓存可能存在的并行写，实现串行写



#### 9.2.2 实现数据的最终一致性

1、先淘汰缓存，再写数据库

先淘汰缓存，即使写数据库发生异常，也就是下次缓存读取时，多读取一次数据库。这种情况可能存在缓存清理完，写DB的间隙，有一个读操作，又再次把数据读取到缓存中。

那间隙出现读取，导致再次读取到旧数据，怎么解决？引入分布式锁。

* 在写请求时，在淘汰缓存之前，先获取该分布式锁
* 在读请求时，发现缓存不存在时，先获取分该布式锁。

![](../.gitbook/assets/image%20%28121%29.png)

2、先写数据库，再更新缓存

按照”先写数据库，再更新缓存“，要保证DB 和 缓存的操作，能够在”同一个事务“中，从而实现最终一致性。

（1）基于定时任务来实现

* 首先，写入数据库。
* 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。
* 【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。

（2）基于消息队列来实现

* 首先，写入数据库。
* 然后，发送带有缓存 KEY 和 VALUE 的事务消息。此时，需要有支持事务消息特性的消息队列，或者我们自己封装消息队列，支持事务消息。
* 【异步】最后，消费者消费该消息，更新到缓存中。

基于定时任务和消息队列，都会有如下问题：

![](../.gitbook/assets/image%20%28122%29.png)

希望的更新缓存顺序是，线程 1 快于线程 2 ，但是实际线程1 晚于线程 2 ，导致数据不一致。

那么如何解决图中的问题呢？

* 1、在缓存值中，拼接上数据版本号或者时间戳。例如说：`value = {value: 原值, version: xxx}` 。
* 2、在任务表的记录，或者事务消息中，增加上数据版本号或者时间戳的字段。
* 3、在定时任务或消息队列执行更新缓存时，先读取缓存，对比版本号或时间戳，大于才进行更新。😈 当然，此处也会有并发问题，所以还是得引入分布式锁或 CAS 操作。

（3）基于数据库的binlog 日志

![](../.gitbook/assets/image%20%28119%29.png)



#### 9.2.3 大总结

> 使用缓存过程中，经常会遇到缓存数据的不一致性和脏读现象。一般情况下，采取缓存双淘汰机制，在更新数据库的**前**淘汰缓存。此外，设定超时时间，例如三十分钟。
>
> **极端场景下，即使有脏数据进入缓存，这个脏数据也最存在一段时间后自动销毁。**

## 10 缓存预热

### 10.1 为什么缓存预热？

> 在刚启动的缓存系统中，如果缓存中没有任何数据，如果依靠用户请求的方式重建缓存数据，那么对数据库的压力非常大，而且系统的性能开销也是巨大的。
>
> 此时，最好的策略是启动时就把热点数据加载好。这样，用户请求时，直接读取的就是缓存的数据，而无需去读取 DB 重建缓存数据。

### 10.2 如何实现？

1. 数据量不大时，项目启动时，自动进行初始化。

## 11 缓存淘汰策略

除了缓存服务器自带的缓存**自动**失效策略之外，我们还可以根据具体的业务需求进行自定义的**“手动”**缓存淘汰，常见的策略有两种：

* 1、定时去清理过期的缓存。
* 2、当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。

## 12 缓存存储pojo 对象 

* 方案一，将 POJO 对象**序列化**进行存储，适合 Redis 和 Memcached 。
  * 可参考 [《Redis 序列化方式StringRedisSerializer、FastJsonRedisSerializer 和 KryoRedisSerializer》](https://blog.csdn.net/xiaolyuh123/article/details/78682200) 文章。
  * 对于 POJO 对象比较大，可以考虑使用压缩算法，例如说 Snappy、zlib、GZip 等等。
* 方案二，使用 Hash 数据结构，适合 Redis 。
  * 可参考 [《Redis 之序列化 POJO》](https://my.oschina.net/yuyidi/blog/499951) 文章。

