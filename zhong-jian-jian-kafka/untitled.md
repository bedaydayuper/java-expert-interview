# 深入理解kafka

## 1 初始kafka

1、主题是一个逻辑上的概念，可以细分为多个分区。

同一主题下的不同分区包含的消息是不同的。

kafka 保证的是分区有序而不是主题有序。

2、leader 副本 负责读与写，而replica 副本 值负责与leader 副本的消息同步。replica 是用于容灾。  


3、

![](../.gitbook/assets/image%20%2819%29.png)





## 2 生产者

1、消息对象的结构

```text
public class ProducerRecord<K, V> {
    private final String topic; // 主题
    private final integer partition; // 分区号
    private final Headers headers; // 消息头部
    private final K key; // 键
    private final V value; // 值
    private final Long timestamp; // 消息时间戳
    // 省略其他成员方法和构造方法
}
```

key: 可以用来指定消息的键，不进是消息的附加信息，还可以用来计算分区号，进而可以让消息发往特定的分区。同一个key 的消息会被划分到同一个分区中。



2、构建生产者

构建生产者，至少需要如下参数：

```text
bootstrap.servers:  broker 地址清单
key.serializer 和 value.serializer: broker 端接收的消息必须以字节数组的形式存在。
在发往broker 之前，都要使用序列化器进行转换成字节数组。
看了一下 org.apache.kafka.common.serialization.StringSerializer, 就是一个StringCoding.encode.


```

3、消息体构建 ProducerRecord

topic

value

Header

4、发送的类型

发后即忘： 消息丢失  
同步：需要等待，性能差  
异步：可以获取其对应的结果，也可以不捕获



5、分区器

在发往broker的过程中，如果没有指定partition字段，那么就需要依赖分区器。分区器需要依赖消息对象 productRecord 的key 字段、主题、值、以及集群的元数据信息。

> 如果key 不为null, 那么计算得到的分区号会是所有分区中的任意一个； 如果key 为 null, 那么计算得到的分区号仅为可用分区中的任意一个。

消息在分区内是有序的，如果某个业务需要按照某个规则有序，则可以自定义分区器。比如商品属于某个仓库，则存储商品时，可以按照商品的仓库信息进行 分区。

6、拦截器

拦截器分为生产者拦截器和消费者拦截器。

生产者拦截器既可以用来在消息发送前做一些准备工作，比如过滤消息，修改消息内容，也可以用来在发送回调逻辑前做一些定制化的需求。

7、整体架构

![](../.gitbook/assets/image%20%2850%29.png)

  
整个发送过程由主线程 和 sender 线程协调运行。

![](../.gitbook/assets/image%20%2851%29.png)

> 主线程负责创建消息，然后通过拦截器、序列化器和分区器的作用之后，缓存到消息累加器；

> sender 线程负责从消息累加器中获取消息并将其发送到kafka 中。

消息累加器 RecordAccumulator 用来缓存消息以便sender 线程可以批量发送，进而减少网络的资源消耗。

元数据：是指kafka集群的元数据, 这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader 副本分配在哪个节点上，follower  副本分配在哪些节点上，哪些副本在AR、ISR 等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。

Sender 线程会定期获取具体的元信息数据。



8、一些重要的生产者参数

（1）acks

用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是写入成功的。

（2）max.request.size:

用来限制生产者客户端能发送的消息的最大值，默认1M。

（3）retries 和 retry.backoff.ms

retries : 配置生产者重试的次数

retry.backoff.ms: 两次重试之间的时间间隔。



## 3 消费者

### 3.1 消费者基础知识

1、消费者：负责订阅kafka 中的主题，并且从订阅的主题上拉取消息。`【实际的应用案例】`

消费组（consumer group）：每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。`【逻辑上的概念】`

2、每个消费者只能消费所分配到的分区中的消息。

3、对于分区数固定的情况，以为增加消费者并不会让消费能力一直得到提升，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。

4、一个正常的消费逻辑需要具备如下几个步骤：

```text
1、创建消费者实例
2、订阅主题
3、拉取消息并消费
4、提交消费位移
5、关闭消费者实例
```

5、消费者客户端 实例分析

一些必须的参数：

```text
bootstrap.servers: 集群broker 的地址
group.id: 消费者隶属的消费组的名称
key.deserializer 和 value.deserializer: 反序列化方法
client.id: 客户端id , 如果不设置，系统会自动生成一个。
```

6、订阅主题与分区

消费者不仅可以订阅主题，还可以直接订阅某些主题的特定分区。如果想获取具体的分区消息，可以通过partitonFor 方法获取。

当消费组内的消费者增加或者减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。

7、消息 ConsumerRecord

```text
topic: 主题
partition： 分区编号
offset: 消息在所属分区的偏移量
key 和 value ： 消息的键和消息的值
serializedKeySize 和 serializedValueSize: key 和value 经过序列化后的大小

```

8、位移提交

offset :  

对于消息在分区中的位置，称之为 `”偏移量“`；  
对于消费者消费到的位置，称之为`”位移“`，或者叫`消费位移`。

消费者在消费完消息之后需要执行消费位移的 `提交`，将消费位移持久化。

```text
lastConsumerOffset: 表示下一条需要拉取的消息的位置。
committed offset: 已经提交过的消费位移。
```

kafka 可以通过设置enable.auto.commit 来配置自动提交，也可以通过auto.commit.interval.ms 配置提交间隔。

自动位移提交的方式在正常情况下不会发生消息丢失或者消息重复，但是在编程的世界中异常无可避免。 也可以设置为手动提交，这样就能控制消息的提交。

手动提交又分为同步提交和异步提交。

9、控制或者关闭消费

暂停某些分区消费：pause（）

恢复某些分区消费：resume\(\)

10、指定位移消费  auto.offset.reset 

当kafka中每当消费者查找不到所记录的消费位移时，会根据消费者客户端参数auto.offset.reset 的配置来决定从何处开始进行消费。

latest: 表示从分区末尾开始消费消息。  
earliest: 表示从起始处，也就是0开始消费。  
none: 如果没有消费位移记录，就报错。



seek\(\) 方法可以指定在某个partition的某个offset 开始消费。执行之前，需要执行assignment, 来查看当前client 分到的partition。



offsetsForTimes\(\) 通过timestamp 来查询与此对应的分区位置。

经典场景：

```text
通过offsetsForTimes 查找某个时间之前的消息位置，然后通过seek 追溯到相应位置开始消费。
```

11、再均衡

> 再均衡是指分区的所属权从一个消费者转移到另一消费者的行为。在再均衡发生期间，消费组内的消费者是无法读取消息的。也就是再均衡期间，消费组会变得不可用。

再均衡器用来设定发生再均衡动作前后的一些准备或收尾的动作。

onPartitionRevoked: 再均衡开始前和消费者停止读消息之后被调用；

onPartitionsAssigned: 在重新分配分区之后和消费者开始读取消费之前被调用。

12、消费者拦截器

对消息做一些特殊处理

13、多线程实现

多线程的目的就是为了提高整体的消费能力。  


![](../.gitbook/assets/image%20%2854%29.png)

一个线程对应一个kafkaConsumer 实例，也称为 消费线程。

也可以提高消息处理的能力，比如使用线程池处理，如下的模型：

![](../.gitbook/assets/image%20%2853%29.png)







### 3.2 消费者整体流程-源码解析：

参考：  
[https://www.cnblogs.com/dennyzhangdd/p/7759876.html](https://www.cnblogs.com/dennyzhangdd/p/7759876.html)  
[http://yeming.me/2016/12/30/kafkaConsumer/](http://yeming.me/2016/12/30/kafkaConsumer/)

![](../.gitbook/assets/image%20%2855%29.png)

主要流程：

```text
1.容器启动，轮询执行消费。

2.kafkaConsumer拉取消息流程：

1）Fetcher请求获取器获取请求并存储在unset中

2）ConsumerNetworkClient网络客户端执行poll(),调用NetWlrikClient的send()方法从unset中获取ClientRequest请求转成RequestSend最终塞进Selector的KafkaChannel通道中，Seletcor.send()从kafka集群拉取待消费数据ConsumerRecords

3. 消费者监听器MessageListener.onMessage()执行用户自定义的实际消费业务逻辑。
```

 从KafkaConsumer构造函数来看，核心组件有：  


```text
1.Metadata：封装了元数据的一些逻辑的类。元数据仅保留一个主题的子集，随着时间的推移可以添加。当我们请求一个主题的元数据时，我们没有任何元数据会触发元数据更新。如果对元数据启用了主题过期，那么在更新之后，在过期时间间隔内未使用的任何主题都将从元数据刷新集中删除。
2.ConsumerNetworkClient：高等级消费者访问网络层，为请求Future任务提供基本支持。这个类是线程安全的，但是不提供响应回调的同步。这保证在调用它们时不会持有锁。
3.SubscriptionState：订阅的TopicPartition的offset状态维护
4.ConsumerCoordinator：消费者的协调者，负责partitiion的分配，reblance
5.Fetcher：从brokers上按照配置获取消息。
```











## 4 主题与分区

### 4.1、主题的管理

1、主题、分区、副本和log 的关系

![](../.gitbook/assets/image%20%2852%29.png)

主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是Log层才有实际的物理上的存在。

```text
topic 和 partition 表示主题和分区；
partitionCount 表示主题中分区的个数
ReplicationFactor 表示副本因子
Configs 表示创建或者修改主题时指定的参数配置
Leader 表示分区leader 副本所在的brokerid
Isr 表示分区ISR集合
Replicas 表示分区的所有的副本分配情况
```

2、分区分配

这儿是指为集群指定创建主题时的分区副本分配方案，即在哪个broker 中创建哪些分区的副本。

### 4.2 kafkaAdminClient

主题管理类的功能集成到公司内部的系统中，实现管理、监控、运维、告警等，kafkaAdminClient 就提供了这样的API。

### 4.3 分区的管理

#### 4.3.1 优先副本的选举

1、只有leader副本对外提供读写服务，而follower 副本只负责在内部进行消息的同步。

leader 副本所在的broker节点叫做分区的leader节点，而follower 副本所在的broker节点 叫做分区的follower 节点。

2、优先副本：在AR集群列表中的第一个副本，理想情况下优先副本是该分区的leader副本。

优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，一次来促进集群的负载均衡。也称为 ”分区平衡“。

#### 4.3.2  分区重分配



当集群中新增broker 节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中。这样新节点的负载和原先节点负载 就严重不平衡了。

原理：

```text
先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那儿复制所有的数据。

根据分区的大小不同，复制过程可能需要花费一些时间。在复制完成之后，控制器将旧副本从副本清单中移除。
```

分区重分配对集群的性能影响很大，需要占用额外的资源。

#### 4.3.3  复制限流

对副本间的复制进行限流。

### 4.4 如何选择合适的分区数--没有固定的答案，视情况而定。

1、通过压测工具（kafka-producer-perf-test.sh）来进行预估。



## 5 日志存储

### 5.1 文件目录布局

1、 日志关系

![&#x65E5;&#x5FD7;&#x5173;&#x7CFB;](../.gitbook/assets/image%20%2860%29.png)



### 5.2 日志索引

每个日志分段文件对应了两个索引文件，主要是用来提高查找消息的效率。

```text
偏移量索引文件：用来建立消息偏移量到物理地址之间的映射关系；
时间戳索引文件：根据给定的时间戳来查找对应的偏移量信息。
```

偏移量索引：并不是每一条记录都有索引，而是隔一段记录一个偏移量索引。查询时，返回不大于查询值的最大索引。



### 5.3 日志清理

1、两种日志清理策略：

```text
（1）日志删除：按照一定策略直接删除
（2）日志压缩：针对每个消息的key 进行整合，对于有相同key 的不同value 值，
只保留最后一个版本。
```

2、日志删除

```text
（1）基于时间：默认保留7天。
先标记为".deleted" ,然后由延迟任务来执行删除。

（2）基于日志大小：文件大小超过设定的阈值，来进行删除。

（3）基于日志起始偏移量：
```

3、日志压缩

![](../.gitbook/assets/image%20%2857%29.png)

4、

### 5.4 磁盘存储

kafka 只能在日志文件的末尾追加新的消息，并且也不允许修改已写入的消息。

kafka 使用磁盘，但是吞吐量比较高，是因为有如下一些措施：

```text
1、顺序写盘。
2、页缓存
利用内存作为磁盘的缓存，读写先跟页缓存 进行交互，然后当脏页数量达到内存百分比之后，触发flush.
3、零拷贝:
直接将数据从磁盘文件复制到网卡设备中，而不需要经由应用程序。
大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。
```



## 6 深入服务端

### 6.1 协议设计

生产者 的发送跟接收

```text
productRequest
productResponse
```

  
拉取消息：

```text
FetchRequest
FetchResponse
```

### 6.2 时间轮

kafka 存在大量的延时操作，但是kafka 并没有使用JDK自带的Timer 或者DelayQueue 来实现延时的功能。而是基于时间轮的概念自定义实现了一个用于延时功能的定时器。性能高。

![&#x591A;&#x5C42;&#x65F6;&#x95F4;&#x8F6E;](../.gitbook/assets/image%20%2856%29.png)

类似于钟表 的秒针、分针和时针。

### 6.3 延时操作

1、在kafka 中 有多种延时操作。延时操作需要延时返回响应的结果；其次延时操作可以在设定超时时间之前完成，所以延时操作能够支持外部事件的触发。

2、延时操作创建之后会被加入延时操作管理器来做专门的处理。延时操作有可能会超时，每个延时操作管理器都会配备一个定时器来做超时管理，定时器的底层就是采用时间轮实现的。

3、延时操作需要支持外部事件的触发，所以还要配备一个监听池来负责监听每个分区的外部事件，查看是否有分区的HW 发生了增长。

![](../.gitbook/assets/image%20%2859%29.png)

4、同样，拉取也有延时操作。

### 6.4 控制器

1、集群中有多个broker，其中有一个broker 会被选举为控制器，它负责整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。当检测到某个分区的ISR集合发生变换时，由控制器负责通知所有broker更新其元数据信息。

2、控制器的选举以及异常恢复

由zk 控制。

控制器的纪元：记录当前的控制器是第几代。初始值为1，后续当控制器发生变更时，该值加一。



3、分区leader的选举

由控制器负责具体的实施。

策略：按照AR集合中副本的顺序查找第一个存活的副本，秉着这个副本在ISR集合中。





## 7 深入客户端

### 7.1 分区分配策略

1、RangeAssignor 分配策略：按照消费者总数和分区总数进行整除来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。



2、RoundRobinAssignor 分配策略：将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮训的方式逐个将分区依次分配给每个消费者。  


3、自定义分区分配策略：实现partitionAssignor 接口。

事实：按照kafka 默认的消费逻辑设定，一个分区内只能被同一个消费组内的一个消费者消费。但这一设定不是绝对的，可以通过自定义分区分配策略是一个分区可以分配给多个消费者消费。

比如组内广播：

![](../.gitbook/assets/image%20%2858%29.png)

组内广播 会有一个严重的问题：默认的消费位移的提交就会失效。如果要真正实现组内广播，则需要自己保存每个消费者的消费位移。



### 7.2 消费者协调器和组协调器

1、依赖zk 的弊端：

```text
（1）羊群效应：zk 中一个被监听的节点变化，大量watcher 通知被发送到客户端，
导致在通知期间的其他操作延迟。

（2）脑裂问题：同一时刻，各个消费者获取的状态不一致。
```

2、新版使用了  
GroupCoordinator, 服务端用于管理消费组的组件。  
ConsumerCoordinator, 客户端组件，负责与GroupCoordinator 交互。

3、再均衡 

借助ConsumerCoordinator 与GroupCoordinator ，执行消费者再均衡的操作。

再均衡的场景：

```text
1、新消费者加入消费组
2、有消费者宕机下线
3、有消费者主动退出消费组
4、消费组对应的GroupCoornator 节点发生了变化
5、消费组内所订阅的任一主题或者主题的分片数量发生变化。

```

新节点加入group的再均衡阶段：

```text
1 find coordinator
2 join group
3 sync group 
4 heartbeat
```

4、选举消费组的leader

GroupCoordinator 为消费组内的消费者选举一个消费者的leader。

机制：

如果消费组内还没有，则选择第一个进入的消费者作为leader。  
如果某一时刻leader消费者退出了消费组，则随机选一个新leader 消费者。

5、选举分区分配策略

消费组内各个消费者投票决定最终用哪个。

### 7.3 \_consumer\_offsets 剖析

位移提交会保存在kafka 内部主题 \_\_consumer offsets 中。

偏移值一般默认保留7天，超过了则被删除，消费者再次消费时，只能根据参数，是决定从lastest 还是earliest 开始消费。



### 7.4 事务

1、幂等

对接口的多次调用所产生的结果和调用一次是一致的。此时就不会有消息重复。

需要 借助 producer id 和 序列号 sequence number 来实现。



2、事务

幂等性并不能跨多个分区运作，而事务可以弥补这个缺陷，可以保证对多个分区写入操作的原子性。

可以使应用程序将消费消息、生产消息、提交消费位移当做原子操作来处理，同时成功或失败。

引入了transactionid.



## 8 可靠性研究



## 9 高级应用 （11章）



## 疑问:

1、服务端消息保存多久？

2、消费者可以从某个时间点之前的位移处开始消费，这些位移信息是怎么保存的？另外，从位移之后的消息也会持久化？

3、

